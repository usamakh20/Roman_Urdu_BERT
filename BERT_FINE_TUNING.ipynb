{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'multilingual_vocab_extension'\n",
    "\n",
    "# !transformers-cli convert --model_type bert \\\n",
    "#   --tf_checkpoint $MODEL_PATH/model.ckpt-100000 \\\n",
    "#   --config $MODEL_PATH/config.json \\\n",
    "#   --pytorch_dump_output $MODEL_PATH/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pprint\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import Trainer, TrainingArguments,DataCollatorWithPadding,DataCollatorForTokenClassification,BertForQuestionAnswering,BertForSequenceClassification,BertForTokenClassification,BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on:  cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = '../glue-urdu/'\n",
    "TASK = 'SentiMix'\n",
    "SAVE_PATH = 'fine_tune_results/{}/{}'.format(TASK,MODEL_PATH)\n",
    "task_params = {\n",
    "    'NER':{'best_model_metric':'eval_f1','entity_metrics':False,'batch_size':30, 'epochs':6, 'eval_steps':50 },\n",
    "    'NLI':{'best_model_metric':'eval_f1','batch_size':30, 'epochs':5, 'eval_steps':100},\n",
    "    'POS':{'best_model_metric':'eval_f1','entity_metrics':False,'batch_size':30, 'epochs':30, 'eval_steps':10 },\n",
    "    'QuAD':{'best_model_metric':'eval_f1','batch_size':30, 'epochs':10, 'eval_steps':10},\n",
    "    'SentiMix':{'best_model_metric':'eval_f1','batch_size':30, 'epochs':5, 'eval_steps':50}\n",
    "}\n",
    "max_length = 128 # The maximum length of a feature (question and context)\n",
    "doc_stride = 32 # The authorized overlap between two part of the context when splitting it is needed.\n",
    "assert TASK in task_params.keys()\n",
    "hyperparams = task_params[TASK]\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "print(\"Training on: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels,tokenizer_fn=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.tokenizer_fn = tokenizer_fn\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if TASK == 'NLI':\n",
    "            item = {key: torch.squeeze(val) for key, val in self.tokenizer_fn(self.encodings[idx]).items()}\n",
    "            # item = {key: torch.squeeze(val) for key, val in self.tokenizer_fn(self.encodings[idx]).items()}\n",
    "        else:\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "        if TASK == 'POS' or TASK == 'NER':\n",
    "            item['labels'] = self.labels[idx]\n",
    "        elif TASK != 'QuAD':\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        if TASK == 'NLI':\n",
    "            return len(self.labels)\n",
    "        else:\n",
    "            return len(self.encodings['input_ids'])\n",
    "\n",
    "def random_bias(from_num,to_num,high=True):\n",
    "    return math.floor(abs(int(high) - abs(random.random() - random.random())) * (1 + to_num - from_num) + from_num)\n",
    "\n",
    "def preprocess_data(sentences, answers, max_untokenized_len = 100):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    corrected_indices = 0\n",
    "    for sentence,answer in zip(sentences,answers):\n",
    "        start_idx = sentence[1].index(answer[1])\n",
    "        end_idx = start_idx + len(answer[1])\n",
    "        corrected_indices += start_idx != int(answer[0])\n",
    "        assert sentence[1][start_idx:end_idx] == answer[1]\n",
    "        if len(answer[1].split())+len(sentence[0].split()) < max_untokenized_len:\n",
    "            if len(sentence[0].split())+len(sentence[1].split()) < max_untokenized_len:\n",
    "                X.append((sentence[0],sentence[1]))\n",
    "                y.append(((start_idx,answer[1]),sentence[1]))\n",
    "            else:\n",
    "                start_extra_len = len(sentence[1][:start_idx].split())\n",
    "                end_extra_len =  len(sentence[1][end_idx:].split())\n",
    "                while True:\n",
    "                    random_start = random_bias(0,start_extra_len)\n",
    "                    random_end = random_bias(0,end_extra_len)\n",
    "                    if random_start+random_end+len(answer[1].split()) < max_untokenized_len:\n",
    "                        new_start = start_extra_len - random_start\n",
    "                        new_end = len(sentence[1][:end_idx].split()) + random_end\n",
    "                        X.append([sentence[0],' '.join(sentence[1].split()[new_start:new_end])])\n",
    "                        y.append([(X[-1][1].index(answer[1]), answer[1]), X[-1][1]])\n",
    "                        assert X[-1][1][y[-1][0][0]:y[-1][0][0]+len(answer[1])] == answer[1]\n",
    "                        break\n",
    "\n",
    "\n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def prepare_features(data, answers):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        list(data[:, 0]),\n",
    "        list(data[:, 1]),\n",
    "        padding='max_length',\n",
    "        truncation='only_second',\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        stride=doc_stride\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = list(input_ids).index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answer = answers[sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answer[0][1]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answer[0][0]\n",
    "            end_char = start_char + len(answer[0][1])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = sequence_ids.index(1)\n",
    "\n",
    "            offset_mapping[i][:token_start_index] = torch.tensor([[-1] * 2] * token_start_index)\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    features_dict = {\n",
    "        'offset_mapping':offset_mapping,\n",
    "        'example_id': sample_mapping.numpy(),\n",
    "        'input_ids':tokenized_examples['input_ids']\n",
    "    }\n",
    "    return tokenized_examples, (answers, features_dict )\n",
    "\n",
    "def encode_tags(tags, encodings, unique_tags):\n",
    "    labels = [[unique_tags.index(tag) for tag in doc] for doc in tags]\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        # create an empty array of -100\n",
    "        doc_enc_labels = np.ones(len(doc_offset), dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "        if sum(arr_offset[-2]) != 0:\n",
    "            sub_len = sum((arr_offset[:, 0] == 0) & (arr_offset[:, 1] != 0))\n",
    "        else:\n",
    "            sub_len = len(doc_labels)\n",
    "        doc_enc_labels[(arr_offset[:, 0] == 0) & (arr_offset[:, 1] != 0)] = doc_labels[:sub_len]\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "    return encoded_labels\n",
    "\n",
    "def common_NER_POS(token_tags,num_tags):\n",
    "    unique_tags = list(set(tag for doc in token_tags[0][1] + token_tags[1][1] for tag in doc))\n",
    "    assert len(unique_tags) == num_tags\n",
    "    X_train, X_val, y_train, y_val = train_test_split(*token_tags[0], test_size=0.1)\n",
    "    X_test, y_test = token_tags[1]\n",
    "\n",
    "    encodings = []\n",
    "    labels = []\n",
    "    for data, label in [(X_train, y_train), (X_val, y_val), (X_test, y_test)]:\n",
    "        encodings.append(\n",
    "            tokenizer(list(data), is_split_into_words=True, return_offsets_mapping=True, padding='max_length',\n",
    "                      truncation=True, add_special_tokens=True, return_attention_mask=True,\n",
    "                      return_tensors=\"pt\", max_length=max_length))\n",
    "        labels.append(encode_tags(label, encodings[-1], unique_tags))\n",
    "        encodings[-1].pop(\"offset_mapping\")\n",
    "\n",
    "    CustomDataset.label_list = unique_tags\n",
    "    return {'train': CustomDataset(encodings[0], labels[0]),\n",
    "            'dev': CustomDataset(encodings[1], labels[1]),\n",
    "            'test': CustomDataset(encodings[2], labels[2])}\n",
    "\n",
    "def getSentiMix(path):\n",
    "    senti_mix_train = pd.read_csv(path+'SentiMix/Roman Urdu/SentiMix.train.ru.csv')\n",
    "    senti_mix_test = pd.read_csv(path+'SentiMix/Roman Urdu/SentiMix.test.ru.csv')\n",
    "    sentiment_categorical = senti_mix_train['sentiment'].astype('category').cat\n",
    "    class_names = list(sentiment_categorical.categories)\n",
    "\n",
    "    sentences_train = list(senti_mix_train.sentence)\n",
    "    labels_train = list(sentiment_categorical.codes)\n",
    "\n",
    "    X_test = list(senti_mix_test.sentence)\n",
    "    y_test = list(senti_mix_test['sentiment'].astype('category').cat.codes)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(sentences_train, labels_train, test_size=0.1)\n",
    "    encodings = []\n",
    "    for data in [X_train,X_val,X_test]:\n",
    "        encodings.append(tokenizer(data,padding='max_length', truncation=True, add_special_tokens = True, return_attention_mask = True, return_tensors = \"pt\", max_length=max_length))\n",
    "\n",
    "    return {'train': CustomDataset(encodings[0],y_train),\n",
    "            'dev': CustomDataset(encodings[1],y_val),\n",
    "            'test': CustomDataset(encodings[2],y_test),\n",
    "            'classes':class_names}\n",
    "\n",
    "def getNLI(path):\n",
    "    data_dict = {}\n",
    "    for i in ['train','dev','test']:\n",
    "        dataframe = pd.read_csv(path+'NLI/Roman Urdu/NLI.ru.{}.tsv'.format(i),sep='\\t')\n",
    "        sentences = dataframe[['premise','hypo']].to_numpy()\n",
    "        categorical = dataframe['Label'].astype('category').cat\n",
    "        labels = list(categorical.codes)\n",
    "        data = [tuple(map(str.strip,sentence)) for sentence in sentences]\n",
    "        tokenizer_fn = lambda x: tokenizer(*x,padding='max_length', truncation=True, add_special_tokens = True, return_attention_mask = True,return_tensors = \"pt\", max_length=max_length)\n",
    "        data_dict[i] = CustomDataset(data,labels,tokenizer_fn)\n",
    "        if i == 'train':\n",
    "            data_dict['classes'] = list(categorical.categories)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def getNER(path):\n",
    "    token_tags = []\n",
    "    for split_type in ['train', 'test']:\n",
    "        raw_docs = open(path + 'NER/Roman Urdu/NER.ru.{}'.format(split_type)).read().strip().split('\\n\\n')\n",
    "        processed_docs = [list(zip(*[token_tag.split('\\t') for token_tag in doc.split('\\n')])) for doc in raw_docs]\n",
    "        token_tags.append(list(zip(*processed_docs)))\n",
    "\n",
    "    return common_NER_POS(token_tags,7)\n",
    "\n",
    "def getPOS(path):\n",
    "    token_tags = []\n",
    "    for split_type in ['train','dev' ,'test']:\n",
    "        raw_docs = open(path + 'POS/Roman Urdu/pos.ru.{}.conllu'.format(split_type)).read().strip().split('\\n\\n')\n",
    "        processed_docs = [list(zip(*[itemgetter(1,3)(token_tag.split('\\t')) for token_tag in doc.split('\\n')[2:]])) for doc in raw_docs]\n",
    "        token_tags.append(list(zip(*processed_docs)))\n",
    "\n",
    "    return common_NER_POS(token_tags,17)\n",
    "\n",
    "def getQuAD(path):\n",
    "    assert tokenizer.padding_side == \"right\"\n",
    "    dataframe = pd.read_csv(path + 'QuAD/Roman Urdu/QuAD.ru.csv', sep=r\"\\s\\|\\s\", engine='python')\n",
    "    sentences = dataframe[[\"question\", \"paragraph\"]].to_numpy()\n",
    "    answers = dataframe[[\"answer starting idx\", \"answer\"]].to_numpy()\n",
    "\n",
    "    X,y = preprocess_data(sentences,answers)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125,\n",
    "                                                      random_state=1)  # 0.125 * 0.8 = 0.1\n",
    "\n",
    "    datasets = {}\n",
    "    for data, answer, split in zip([X_train, X_val, X_test], [y_train, y_val, y_test], ['train', 'dev', 'test']):\n",
    "        datasets[split] = CustomDataset(*prepare_features(data, answer))\n",
    "\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at multilingual_vocab_extension were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at multilingual_vocab_extension and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "fine_tune_dataset = locals()['get'+TASK](DATA_ROOT)\n",
    "eval_dataset = fine_tune_dataset['dev']\n",
    "if TASK == 'QuAD':\n",
    "    metric = load_metric(\"squad\")\n",
    "elif TASK == 'NER' or TASK == 'POS':\n",
    "    metric = load_metric(\"seqeval\")\n",
    "\n",
    "if TASK == 'QuAD':\n",
    "    model = BertForQuestionAnswering.from_pretrained(MODEL_PATH)\n",
    "elif TASK == 'NER' or TASK == 'POS':\n",
    "    model = BertForTokenClassification.from_pretrained(MODEL_PATH,num_labels=len(CustomDataset.label_list))\n",
    "else:\n",
    "    model = BertForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=3)\n",
    "\n",
    "def compute_squad_metrics(pred):\n",
    "    n_best_size = 20\n",
    "    all_start_logits, all_end_logits = pred.predictions\n",
    "    examples, features = eval_dataset.labels\n",
    "    # Build a map example to its corresponding features.\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, example_id in enumerate(features[\"example_id\"]):\n",
    "        features_per_example[example_id].append(i)\n",
    "\n",
    "    # The dictionaries we have to fill.\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    # Let's loop over all the examples!\n",
    "    for example_index, example in enumerate(examples):\n",
    "        # Those are the indices of the features associated to the current example.\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None  # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[1]\n",
    "        # Looping through all the features associated to the current example.\n",
    "        for feature_index in feature_indices:\n",
    "            # We grab the predictions of the model for this feature.\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "            # context.\n",
    "            offset_mapping = features[\"offset_mapping\"][feature_index]\n",
    "\n",
    "            # Update minimum null prediction.\n",
    "            cls_index = list(features[\"input_ids\"][feature_index]).index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "            start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                    # Don't consider answers with a length that is either < 0\n",
    "                    # to part of the input_ids that are not in the context.\n",
    "                    if offset_mapping[start_index][0] == -1 or end_index < start_index:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "            # failure.\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "        predictions.append({'id':str(example_index),'prediction_text': best_answer[\"text\"]})\n",
    "        references.append({'id':str(example_index),'answers':{'answer_start':[example[0][0]],'text':[example[0][1]]}})\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    if TASK == 'QuAD':\n",
    "        return compute_squad_metrics(pred)\n",
    "    elif TASK == 'NER' or TASK == 'POS':\n",
    "        predictions, labels = pred\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions,true_labels = list(zip(*[zip(*map(lambda p_l:itemgetter(*p_l)(CustomDataset.label_list),\n",
    "                                                           filter(lambda p_l: p_l[1] != -100, zip(prediction,label))))\n",
    "                                                  for prediction, label in zip(predictions,labels)]))\n",
    "\n",
    "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "        if hyperparams['entity_metrics']:\n",
    "            # Unpack nested dictionaries\n",
    "            final_results = {}\n",
    "            for key, value in results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for n, v in value.items():\n",
    "                        final_results[f\"{key}_{n}\"] = v\n",
    "                else:\n",
    "                    final_results[key] = value\n",
    "            return final_results\n",
    "        else:\n",
    "            return {\n",
    "                \"precision\": results[\"overall_precision\"],\n",
    "                \"recall\": results[\"overall_recall\"],\n",
    "                \"f1\": results[\"overall_f1\"],\n",
    "                \"accuracy\": results[\"overall_accuracy\"],\n",
    "            }\n",
    "    else:\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=SAVE_PATH,  # output directory\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=hyperparams['epochs'],  # total number of training epochs\n",
    "    per_device_train_batch_size=hyperparams['batch_size'],  # batch size per device during training\n",
    "    per_device_eval_batch_size=hyperparams['batch_size'],  # batch size for evaluation\n",
    "    warmup_steps=60,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='./logs',  # directory for storing logs\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,\n",
    "    eval_steps = hyperparams['eval_steps'],\n",
    "    save_total_limit = 10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=hyperparams['best_model_metric']\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=fine_tune_dataset['train'],  # training dataset\n",
    "    eval_dataset=fine_tune_dataset['dev'],  # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForTokenClassification(tokenizer) if TASK == 'NER' or TASK == 'POS' else DataCollatorWithPadding(tokenizer)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='991' max='1275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 991/1275 14:54 < 04:16, 1.11 it/s, Epoch 3.88/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.862400</td>\n",
       "      <td>0.873601</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.590867</td>\n",
       "      <td>0.599700</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>7.759500</td>\n",
       "      <td>219.086000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.851400</td>\n",
       "      <td>0.840098</td>\n",
       "      <td>0.612353</td>\n",
       "      <td>0.600394</td>\n",
       "      <td>0.608825</td>\n",
       "      <td>0.612353</td>\n",
       "      <td>7.747100</td>\n",
       "      <td>219.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.915100</td>\n",
       "      <td>0.814445</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.626287</td>\n",
       "      <td>0.634701</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>7.752200</td>\n",
       "      <td>219.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.643000</td>\n",
       "      <td>0.813421</td>\n",
       "      <td>0.627647</td>\n",
       "      <td>0.625098</td>\n",
       "      <td>0.629326</td>\n",
       "      <td>0.627647</td>\n",
       "      <td>7.841800</td>\n",
       "      <td>216.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.852800</td>\n",
       "      <td>0.800295</td>\n",
       "      <td>0.628824</td>\n",
       "      <td>0.629303</td>\n",
       "      <td>0.663803</td>\n",
       "      <td>0.628824</td>\n",
       "      <td>7.856200</td>\n",
       "      <td>216.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.765800</td>\n",
       "      <td>0.809333</td>\n",
       "      <td>0.636471</td>\n",
       "      <td>0.632213</td>\n",
       "      <td>0.634134</td>\n",
       "      <td>0.636471</td>\n",
       "      <td>7.852400</td>\n",
       "      <td>216.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.769100</td>\n",
       "      <td>0.782437</td>\n",
       "      <td>0.640588</td>\n",
       "      <td>0.641391</td>\n",
       "      <td>0.643757</td>\n",
       "      <td>0.640588</td>\n",
       "      <td>7.807500</td>\n",
       "      <td>217.741000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.806381</td>\n",
       "      <td>0.625294</td>\n",
       "      <td>0.613414</td>\n",
       "      <td>0.622922</td>\n",
       "      <td>0.625294</td>\n",
       "      <td>7.721900</td>\n",
       "      <td>220.154000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.713400</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.632249</td>\n",
       "      <td>0.633950</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>7.743300</td>\n",
       "      <td>219.546000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>0.794565</td>\n",
       "      <td>0.645882</td>\n",
       "      <td>0.641005</td>\n",
       "      <td>0.642133</td>\n",
       "      <td>0.645882</td>\n",
       "      <td>7.746600</td>\n",
       "      <td>219.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>0.838932</td>\n",
       "      <td>0.639412</td>\n",
       "      <td>0.637936</td>\n",
       "      <td>0.638896</td>\n",
       "      <td>0.639412</td>\n",
       "      <td>7.641200</td>\n",
       "      <td>222.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.757100</td>\n",
       "      <td>0.850897</td>\n",
       "      <td>0.639412</td>\n",
       "      <td>0.637381</td>\n",
       "      <td>0.636527</td>\n",
       "      <td>0.639412</td>\n",
       "      <td>7.617200</td>\n",
       "      <td>223.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.496500</td>\n",
       "      <td>0.861900</td>\n",
       "      <td>0.641176</td>\n",
       "      <td>0.641853</td>\n",
       "      <td>0.643658</td>\n",
       "      <td>0.641176</td>\n",
       "      <td>7.614000</td>\n",
       "      <td>223.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.502200</td>\n",
       "      <td>0.855386</td>\n",
       "      <td>0.641176</td>\n",
       "      <td>0.639131</td>\n",
       "      <td>0.639996</td>\n",
       "      <td>0.641176</td>\n",
       "      <td>7.634100</td>\n",
       "      <td>222.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.454900</td>\n",
       "      <td>0.849522</td>\n",
       "      <td>0.637647</td>\n",
       "      <td>0.636069</td>\n",
       "      <td>0.635799</td>\n",
       "      <td>0.637647</td>\n",
       "      <td>7.626200</td>\n",
       "      <td>222.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>0.942856</td>\n",
       "      <td>0.636471</td>\n",
       "      <td>0.637919</td>\n",
       "      <td>0.644296</td>\n",
       "      <td>0.636471</td>\n",
       "      <td>7.636700</td>\n",
       "      <td>222.608000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.988966</td>\n",
       "      <td>0.624706</td>\n",
       "      <td>0.623877</td>\n",
       "      <td>0.626658</td>\n",
       "      <td>0.624706</td>\n",
       "      <td>7.636900</td>\n",
       "      <td>222.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.331800</td>\n",
       "      <td>1.011321</td>\n",
       "      <td>0.633529</td>\n",
       "      <td>0.634840</td>\n",
       "      <td>0.637079</td>\n",
       "      <td>0.633529</td>\n",
       "      <td>7.641600</td>\n",
       "      <td>222.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.296000</td>\n",
       "      <td>1.042348</td>\n",
       "      <td>0.626471</td>\n",
       "      <td>0.628122</td>\n",
       "      <td>0.631107</td>\n",
       "      <td>0.626471</td>\n",
       "      <td>7.749200</td>\n",
       "      <td>219.377000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_dataset = fine_tune_dataset['test']\n",
    "hyperparams['entity_metrics'] = True\n",
    "test_results=trainer.evaluate(fine_tune_dataset['test'])\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = fine_tune_dataset['dev']\n",
    "validation_results = trainer.evaluate(fine_tune_dataset['dev'])\n",
    "validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL='/best-checkpoint'\n",
    "trainer.save_model(SAVE_PATH+FINAL)\n",
    "with open(SAVE_PATH+FINAL+'/test_results.txt','w') as f:\n",
    "    f.write(pprint.pformat(test_results))\n",
    "with open(SAVE_PATH+FINAL+'/validation_results.txt','w') as f:\n",
    "    f.write(pprint.pformat(validation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r $SAVE_PATH/checkpoint-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
