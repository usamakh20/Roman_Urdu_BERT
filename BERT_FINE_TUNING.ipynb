{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = 'multilingual_vocab_augmentation'\n",
    "\n",
    "# !transformers-cli convert --model_type bert \\\n",
    "#   --tf_checkpoint $MODEL_PATH/model.ckpt-100000 \\\n",
    "#   --config $MODEL_PATH/config.json \\\n",
    "#   --pytorch_dump_output $MODEL_PATH/pytorch_model.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pprint\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers.trainer_utils import IntervalStrategy\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import Trainer, TrainingArguments,DataCollatorWithPadding,DataCollatorForTokenClassification,BertForQuestionAnswering,BertForSequenceClassification,BertForTokenClassification,BertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on:  cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = '../glue-urdu/'\n",
    "TASK = 'SentiMix'\n",
    "SAVE_PATH = 'fine_tune_results/{}/{}'.format(TASK,MODEL_PATH)\n",
    "task_params = {\n",
    "    'NER':{'best_model_metric':'eval_f1','entity_metrics':False,'batch_size':30, 'epochs':6, 'eval_steps':50 },\n",
    "    'NLI':{'best_model_metric':'eval_f1','batch_size':30, 'epochs':5, 'eval_steps':100},\n",
    "    'POS':{'best_model_metric':'eval_f1','entity_metrics':False,'batch_size':30, 'epochs':30, 'eval_steps':10 },\n",
    "    'QuAD':{'best_model_metric':'eval_f1','batch_size':30, 'epochs':10, 'eval_steps':10},\n",
    "    'SentiMix':{'best_model_metric':'eval_f1','batch_size':30, 'epochs':5, 'eval_steps':50}\n",
    "}\n",
    "max_length = 128 # The maximum length of a feature (question and context)\n",
    "doc_stride = 32 # The authorized overlap between two part of the context when splitting it is needed.\n",
    "assert TASK in task_params.keys()\n",
    "hyperparams = task_params[TASK]\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH)\n",
    "print(\"Training on: \",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels,tokenizer_fn=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.tokenizer_fn = tokenizer_fn\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if TASK == 'NLI':\n",
    "            item = {key: torch.squeeze(val) for key, val in self.tokenizer_fn(self.encodings[idx]).items()}\n",
    "            # item = {key: torch.squeeze(val) for key, val in self.tokenizer_fn(self.encodings[idx]).items()}\n",
    "        else:\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "        if TASK == 'POS' or TASK == 'NER':\n",
    "            item['labels'] = self.labels[idx]\n",
    "        elif TASK != 'QuAD':\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        if TASK == 'NLI':\n",
    "            return len(self.labels)\n",
    "        else:\n",
    "            return len(self.encodings['input_ids'])\n",
    "\n",
    "def random_bias(from_num,to_num,high=True):\n",
    "    return math.floor(abs(int(high) - abs(random.random() - random.random())) * (1 + to_num - from_num) + from_num)\n",
    "\n",
    "def preprocess_data(sentences, answers, max_untokenized_len = 100):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    corrected_indices = 0\n",
    "    for sentence,answer in zip(sentences,answers):\n",
    "        start_idx = sentence[1].index(answer[1])\n",
    "        end_idx = start_idx + len(answer[1])\n",
    "        corrected_indices += start_idx != int(answer[0])\n",
    "        assert sentence[1][start_idx:end_idx] == answer[1]\n",
    "        if len(answer[1].split())+len(sentence[0].split()) < max_untokenized_len:\n",
    "            if len(sentence[0].split())+len(sentence[1].split()) < max_untokenized_len:\n",
    "                X.append((sentence[0],sentence[1]))\n",
    "                y.append(((start_idx,answer[1]),sentence[1]))\n",
    "            else:\n",
    "                start_extra_len = len(sentence[1][:start_idx].split())\n",
    "                end_extra_len =  len(sentence[1][end_idx:].split())\n",
    "                while True:\n",
    "                    random_start = random_bias(0,start_extra_len)\n",
    "                    random_end = random_bias(0,end_extra_len)\n",
    "                    if random_start+random_end+len(answer[1].split()) < max_untokenized_len:\n",
    "                        new_start = start_extra_len - random_start\n",
    "                        new_end = len(sentence[1][:end_idx].split()) + random_end\n",
    "                        X.append([sentence[0],' '.join(sentence[1].split()[new_start:new_end])])\n",
    "                        y.append([(X[-1][1].index(answer[1]), answer[1]), X[-1][1]])\n",
    "                        assert X[-1][1][y[-1][0][0]:y[-1][0][0]+len(answer[1])] == answer[1]\n",
    "                        break\n",
    "\n",
    "\n",
    "    return np.array(X),np.array(y)\n",
    "\n",
    "def prepare_features(data, answers):\n",
    "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        list(data[:, 0]),\n",
    "        list(data[:, 1]),\n",
    "        padding='max_length',\n",
    "        truncation='only_second',\n",
    "        add_special_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=max_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        stride=doc_stride\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will label impossible answers with the index of the CLS token.\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = list(input_ids).index(tokenizer.cls_token_id)\n",
    "\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answer = answers[sample_index]\n",
    "        # If no answers are given, set the cls_index as answer.\n",
    "        if len(answer[0][1]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            # Start/end character index of the answer in the text.\n",
    "            start_char = answer[0][0]\n",
    "            end_char = start_char + len(answer[0][1])\n",
    "\n",
    "            # Start token index of the current span in the text.\n",
    "            token_start_index = sequence_ids.index(1)\n",
    "\n",
    "            offset_mapping[i][:token_start_index] = torch.tensor([[-1] * 2] * token_start_index)\n",
    "\n",
    "            # End token index of the current span in the text.\n",
    "            token_end_index = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)\n",
    "\n",
    "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    features_dict = {\n",
    "        'offset_mapping':offset_mapping,\n",
    "        'example_id': sample_mapping.numpy(),\n",
    "        'input_ids':tokenized_examples['input_ids']\n",
    "    }\n",
    "    return tokenized_examples, (answers, features_dict )\n",
    "\n",
    "def encode_tags(tags, encodings, unique_tags):\n",
    "    labels = [[unique_tags.index(tag) for tag in doc] for doc in tags]\n",
    "    encoded_labels = []\n",
    "    for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
    "        # create an empty array of -100\n",
    "        doc_enc_labels = np.ones(len(doc_offset), dtype=int) * -100\n",
    "        arr_offset = np.array(doc_offset)\n",
    "\n",
    "        # set labels whose first offset position is 0 and the second is not 0\n",
    "        if sum(arr_offset[-2]) != 0:\n",
    "            sub_len = sum((arr_offset[:, 0] == 0) & (arr_offset[:, 1] != 0))\n",
    "        else:\n",
    "            sub_len = len(doc_labels)\n",
    "        doc_enc_labels[(arr_offset[:, 0] == 0) & (arr_offset[:, 1] != 0)] = doc_labels[:sub_len]\n",
    "        encoded_labels.append(doc_enc_labels.tolist())\n",
    "\n",
    "    return encoded_labels\n",
    "\n",
    "def common_NER_POS(token_tags,num_tags):\n",
    "    unique_tags = list(set(tag for doc in token_tags[0][1] + token_tags[1][1] for tag in doc))\n",
    "    assert len(unique_tags) == num_tags\n",
    "    X_train, X_val, y_train, y_val = train_test_split(*token_tags[0], test_size=0.1)\n",
    "    X_test, y_test = token_tags[1]\n",
    "\n",
    "    encodings = []\n",
    "    labels = []\n",
    "    for data, label in [(X_train, y_train), (X_val, y_val), (X_test, y_test)]:\n",
    "        encodings.append(\n",
    "            tokenizer(list(data), is_split_into_words=True, return_offsets_mapping=True, padding='max_length',\n",
    "                      truncation=True, add_special_tokens=True, return_attention_mask=True,\n",
    "                      return_tensors=\"pt\", max_length=max_length))\n",
    "        labels.append(encode_tags(label, encodings[-1], unique_tags))\n",
    "        encodings[-1].pop(\"offset_mapping\")\n",
    "\n",
    "    CustomDataset.label_list = unique_tags\n",
    "    return {'train': CustomDataset(encodings[0], labels[0]),\n",
    "            'dev': CustomDataset(encodings[1], labels[1]),\n",
    "            'test': CustomDataset(encodings[2], labels[2])}\n",
    "\n",
    "def getSentiMix(path):\n",
    "    senti_mix_train = pd.read_csv(path+'SentiMix/Roman Urdu/SentiMix.train.ru.csv')\n",
    "    senti_mix_test = pd.read_csv(path+'SentiMix/Roman Urdu/SentiMix.test.ru.csv')\n",
    "    sentiment_categorical = senti_mix_train['sentiment'].astype('category').cat\n",
    "    class_names = list(sentiment_categorical.categories)\n",
    "\n",
    "    sentences_train = list(senti_mix_train.sentence)\n",
    "    labels_train = list(sentiment_categorical.codes)\n",
    "\n",
    "    X_test = list(senti_mix_test.sentence)\n",
    "    y_test = list(senti_mix_test['sentiment'].astype('category').cat.codes)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(sentences_train, labels_train, test_size=0.1)\n",
    "    encodings = []\n",
    "    for data in [X_train,X_val,X_test]:\n",
    "        encodings.append(tokenizer(data,padding='max_length', truncation=True, add_special_tokens = True, return_attention_mask = True, return_tensors = \"pt\", max_length=max_length))\n",
    "\n",
    "    return {'train': CustomDataset(encodings[0],y_train),\n",
    "            'dev': CustomDataset(encodings[1],y_val),\n",
    "            'test': CustomDataset(encodings[2],y_test),\n",
    "            'classes':class_names}\n",
    "\n",
    "def getNLI(path):\n",
    "    data_dict = {}\n",
    "    for i in ['train','dev','test']:\n",
    "        dataframe = pd.read_csv(path+'NLI/Roman Urdu/NLI.ru.{}.tsv'.format(i),sep='\\t')\n",
    "        sentences = dataframe[['premise','hypo']].to_numpy()\n",
    "        categorical = dataframe['Label'].astype('category').cat\n",
    "        labels = list(categorical.codes)\n",
    "        data = [tuple(map(str.strip,sentence)) for sentence in sentences]\n",
    "        tokenizer_fn = lambda x: tokenizer(*x,padding='max_length', truncation=True, add_special_tokens = True, return_attention_mask = True,return_tensors = \"pt\", max_length=max_length)\n",
    "        data_dict[i] = CustomDataset(data,labels,tokenizer_fn)\n",
    "        if i == 'train':\n",
    "            data_dict['classes'] = list(categorical.categories)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def getNER(path):\n",
    "    token_tags = []\n",
    "    for split_type in ['train', 'test']:\n",
    "        raw_docs = open(path + 'NER/Roman Urdu/NER.ru.{}'.format(split_type)).read().strip().split('\\n\\n')\n",
    "        processed_docs = [list(zip(*[token_tag.split('\\t') for token_tag in doc.split('\\n')])) for doc in raw_docs]\n",
    "        token_tags.append(list(zip(*processed_docs)))\n",
    "\n",
    "    return common_NER_POS(token_tags,7)\n",
    "\n",
    "def getPOS(path):\n",
    "    token_tags = []\n",
    "    for split_type in ['train','dev' ,'test']:\n",
    "        raw_docs = open(path + 'POS/Roman Urdu/pos.ru.{}.conllu'.format(split_type)).read().strip().split('\\n\\n')\n",
    "        processed_docs = [list(zip(*[itemgetter(1,3)(token_tag.split('\\t')) for token_tag in doc.split('\\n')[2:]])) for doc in raw_docs]\n",
    "        token_tags.append(list(zip(*processed_docs)))\n",
    "\n",
    "    return common_NER_POS(token_tags,17)\n",
    "\n",
    "def getQuAD(path):\n",
    "    assert tokenizer.padding_side == \"right\"\n",
    "    dataframe = pd.read_csv(path + 'QuAD/Roman Urdu/QuAD.ru.csv', sep=r\"\\s\\|\\s\", engine='python')\n",
    "    sentences = dataframe[[\"question\", \"paragraph\"]].to_numpy()\n",
    "    answers = dataframe[[\"answer starting idx\", \"answer\"]].to_numpy()\n",
    "\n",
    "    X,y = preprocess_data(sentences,answers)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125,\n",
    "                                                      random_state=1)  # 0.125 * 0.8 = 0.1\n",
    "\n",
    "    datasets = {}\n",
    "    for data, answer, split in zip([X_train, X_val, X_test], [y_train, y_val, y_test], ['train', 'dev', 'test']):\n",
    "        datasets[split] = CustomDataset(*prepare_features(data, answer))\n",
    "\n",
    "    return datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at multilingual_vocab_augmentation were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at multilingual_vocab_augmentation and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "fine_tune_dataset = locals()['get'+TASK](DATA_ROOT)\n",
    "eval_dataset = fine_tune_dataset['dev']\n",
    "if TASK == 'QuAD':\n",
    "    metric = load_metric(\"squad\")\n",
    "elif TASK == 'NER' or TASK == 'POS':\n",
    "    metric = load_metric(\"seqeval\")\n",
    "\n",
    "if TASK == 'QuAD':\n",
    "    model = BertForQuestionAnswering.from_pretrained(MODEL_PATH)\n",
    "elif TASK == 'NER' or TASK == 'POS':\n",
    "    model = BertForTokenClassification.from_pretrained(MODEL_PATH,num_labels=len(CustomDataset.label_list))\n",
    "else:\n",
    "    model = BertForSequenceClassification.from_pretrained(MODEL_PATH, num_labels=3)\n",
    "\n",
    "def compute_squad_metrics(pred):\n",
    "    n_best_size = 20\n",
    "    all_start_logits, all_end_logits = pred.predictions\n",
    "    examples, features = eval_dataset.labels\n",
    "    # Build a map example to its corresponding features.\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "    for i, example_id in enumerate(features[\"example_id\"]):\n",
    "        features_per_example[example_id].append(i)\n",
    "\n",
    "    # The dictionaries we have to fill.\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    # Let's loop over all the examples!\n",
    "    for example_index, example in enumerate(examples):\n",
    "        # Those are the indices of the features associated to the current example.\n",
    "        feature_indices = features_per_example[example_index]\n",
    "\n",
    "        min_null_score = None  # Only used if squad_v2 is True.\n",
    "        valid_answers = []\n",
    "\n",
    "        context = example[1]\n",
    "        # Looping through all the features associated to the current example.\n",
    "        for feature_index in feature_indices:\n",
    "            # We grab the predictions of the model for this feature.\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            # This is what will allow us to map some the positions in our logits to span of texts in the original\n",
    "            # context.\n",
    "            offset_mapping = features[\"offset_mapping\"][feature_index]\n",
    "\n",
    "            # Update minimum null prediction.\n",
    "            cls_index = list(features[\"input_ids\"][feature_index]).index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            # Go through all possibilities for the `n_best_size` greater start and end logits.\n",
    "            start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "                    # Don't consider answers with a length that is either < 0\n",
    "                    # to part of the input_ids that are not in the context.\n",
    "                    if offset_mapping[start_index][0] == -1 or end_index < start_index:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n",
    "            # failure.\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "        predictions.append({'id':str(example_index),'prediction_text': best_answer[\"text\"]})\n",
    "        references.append({'id':str(example_index),'answers':{'answer_start':[example[0][0]],'text':[example[0][1]]}})\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    if TASK == 'QuAD':\n",
    "        return compute_squad_metrics(pred)\n",
    "    elif TASK == 'NER' or TASK == 'POS':\n",
    "        predictions, labels = pred\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "        # Remove ignored index (special tokens)\n",
    "        true_predictions,true_labels = list(zip(*[zip(*map(lambda p_l:itemgetter(*p_l)(CustomDataset.label_list),\n",
    "                                                           filter(lambda p_l: p_l[1] != -100, zip(prediction,label))))\n",
    "                                                  for prediction, label in zip(predictions,labels)]))\n",
    "\n",
    "        results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "        if hyperparams['entity_metrics']:\n",
    "            # Unpack nested dictionaries\n",
    "            final_results = {}\n",
    "            for key, value in results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    for n, v in value.items():\n",
    "                        final_results[f\"{key}_{n}\"] = v\n",
    "                else:\n",
    "                    final_results[key] = value\n",
    "            return final_results\n",
    "        else:\n",
    "            return {\n",
    "                \"precision\": results[\"overall_precision\"],\n",
    "                \"recall\": results[\"overall_recall\"],\n",
    "                \"f1\": results[\"overall_f1\"],\n",
    "                \"accuracy\": results[\"overall_accuracy\"],\n",
    "            }\n",
    "    else:\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        return {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=SAVE_PATH,  # output directory\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=hyperparams['epochs'],  # total number of training epochs\n",
    "    per_device_train_batch_size=hyperparams['batch_size'],  # batch size per device during training\n",
    "    per_device_eval_batch_size=hyperparams['batch_size'],  # batch size for evaluation\n",
    "    warmup_steps=60,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,  # strength of weight decay\n",
    "    logging_dir='./logs',  # directory for storing logs\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,\n",
    "    eval_steps = hyperparams['eval_steps'],\n",
    "    save_total_limit = 10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=hyperparams['best_model_metric']\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,  # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,  # training arguments, defined above\n",
    "    train_dataset=fine_tune_dataset['train'],  # training dataset\n",
    "    eval_dataset=fine_tune_dataset['dev'],  # evaluation dataset\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForTokenClassification(tokenizer) if TASK == 'NER' or TASK == 'POS' else DataCollatorWithPadding(tokenizer)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1275' max='1275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1275/1275 18:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.095200</td>\n",
       "      <td>1.003113</td>\n",
       "      <td>0.503529</td>\n",
       "      <td>0.495705</td>\n",
       "      <td>0.511208</td>\n",
       "      <td>0.503529</td>\n",
       "      <td>7.324000</td>\n",
       "      <td>232.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.938000</td>\n",
       "      <td>0.933040</td>\n",
       "      <td>0.548824</td>\n",
       "      <td>0.538677</td>\n",
       "      <td>0.543094</td>\n",
       "      <td>0.548824</td>\n",
       "      <td>7.376000</td>\n",
       "      <td>230.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>0.963243</td>\n",
       "      <td>0.525294</td>\n",
       "      <td>0.509602</td>\n",
       "      <td>0.559203</td>\n",
       "      <td>0.525294</td>\n",
       "      <td>7.391100</td>\n",
       "      <td>230.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.889600</td>\n",
       "      <td>0.875008</td>\n",
       "      <td>0.577059</td>\n",
       "      <td>0.576819</td>\n",
       "      <td>0.598950</td>\n",
       "      <td>0.577059</td>\n",
       "      <td>7.397300</td>\n",
       "      <td>229.814000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.880910</td>\n",
       "      <td>0.577647</td>\n",
       "      <td>0.561596</td>\n",
       "      <td>0.571459</td>\n",
       "      <td>0.577647</td>\n",
       "      <td>7.405700</td>\n",
       "      <td>229.554000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.825600</td>\n",
       "      <td>0.863044</td>\n",
       "      <td>0.603529</td>\n",
       "      <td>0.600024</td>\n",
       "      <td>0.600112</td>\n",
       "      <td>0.603529</td>\n",
       "      <td>7.411800</td>\n",
       "      <td>229.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.720500</td>\n",
       "      <td>0.868609</td>\n",
       "      <td>0.581176</td>\n",
       "      <td>0.581948</td>\n",
       "      <td>0.608264</td>\n",
       "      <td>0.581176</td>\n",
       "      <td>7.416900</td>\n",
       "      <td>229.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.817700</td>\n",
       "      <td>0.855442</td>\n",
       "      <td>0.594118</td>\n",
       "      <td>0.595643</td>\n",
       "      <td>0.620538</td>\n",
       "      <td>0.594118</td>\n",
       "      <td>7.427900</td>\n",
       "      <td>228.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.868200</td>\n",
       "      <td>0.868519</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.609063</td>\n",
       "      <td>0.609854</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>7.416600</td>\n",
       "      <td>229.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.585600</td>\n",
       "      <td>0.849635</td>\n",
       "      <td>0.606471</td>\n",
       "      <td>0.602056</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.606471</td>\n",
       "      <td>7.422200</td>\n",
       "      <td>229.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.533000</td>\n",
       "      <td>0.916217</td>\n",
       "      <td>0.599412</td>\n",
       "      <td>0.593937</td>\n",
       "      <td>0.599854</td>\n",
       "      <td>0.599412</td>\n",
       "      <td>7.423200</td>\n",
       "      <td>229.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.895181</td>\n",
       "      <td>0.615882</td>\n",
       "      <td>0.614999</td>\n",
       "      <td>0.615109</td>\n",
       "      <td>0.615882</td>\n",
       "      <td>7.418200</td>\n",
       "      <td>229.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.595900</td>\n",
       "      <td>0.939872</td>\n",
       "      <td>0.604118</td>\n",
       "      <td>0.598276</td>\n",
       "      <td>0.600806</td>\n",
       "      <td>0.604118</td>\n",
       "      <td>7.416700</td>\n",
       "      <td>229.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>0.917889</td>\n",
       "      <td>0.605882</td>\n",
       "      <td>0.606942</td>\n",
       "      <td>0.609555</td>\n",
       "      <td>0.605882</td>\n",
       "      <td>7.392600</td>\n",
       "      <td>229.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.557100</td>\n",
       "      <td>0.964350</td>\n",
       "      <td>0.591176</td>\n",
       "      <td>0.580198</td>\n",
       "      <td>0.592828</td>\n",
       "      <td>0.591176</td>\n",
       "      <td>7.396300</td>\n",
       "      <td>229.843000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.307200</td>\n",
       "      <td>1.080011</td>\n",
       "      <td>0.598824</td>\n",
       "      <td>0.597318</td>\n",
       "      <td>0.597634</td>\n",
       "      <td>0.598824</td>\n",
       "      <td>7.382400</td>\n",
       "      <td>230.277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.409300</td>\n",
       "      <td>1.078259</td>\n",
       "      <td>0.597647</td>\n",
       "      <td>0.599273</td>\n",
       "      <td>0.613407</td>\n",
       "      <td>0.597647</td>\n",
       "      <td>7.427400</td>\n",
       "      <td>228.882000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.531000</td>\n",
       "      <td>1.087723</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.601611</td>\n",
       "      <td>0.613754</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>7.414700</td>\n",
       "      <td>229.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>1.070075</td>\n",
       "      <td>0.609412</td>\n",
       "      <td>0.611131</td>\n",
       "      <td>0.617666</td>\n",
       "      <td>0.609412</td>\n",
       "      <td>7.439600</td>\n",
       "      <td>228.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.733300</td>\n",
       "      <td>1.098690</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.609343</td>\n",
       "      <td>0.609071</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>7.418900</td>\n",
       "      <td>229.145000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.465400</td>\n",
       "      <td>1.159726</td>\n",
       "      <td>0.603529</td>\n",
       "      <td>0.600196</td>\n",
       "      <td>0.601268</td>\n",
       "      <td>0.603529</td>\n",
       "      <td>7.432400</td>\n",
       "      <td>228.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>1.208682</td>\n",
       "      <td>0.604706</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.611924</td>\n",
       "      <td>0.604706</td>\n",
       "      <td>7.434400</td>\n",
       "      <td>228.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.220700</td>\n",
       "      <td>1.178167</td>\n",
       "      <td>0.601176</td>\n",
       "      <td>0.600179</td>\n",
       "      <td>0.602554</td>\n",
       "      <td>0.601176</td>\n",
       "      <td>7.427800</td>\n",
       "      <td>228.869000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>1.197306</td>\n",
       "      <td>0.606471</td>\n",
       "      <td>0.607023</td>\n",
       "      <td>0.609110</td>\n",
       "      <td>0.606471</td>\n",
       "      <td>7.467300</td>\n",
       "      <td>227.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>1.207142</td>\n",
       "      <td>0.608824</td>\n",
       "      <td>0.609328</td>\n",
       "      <td>0.610564</td>\n",
       "      <td>0.608824</td>\n",
       "      <td>7.426800</td>\n",
       "      <td>228.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1275, training_loss=0.6198094613061231, metrics={'train_runtime': 1117.6375, 'train_samples_per_second': 1.141, 'total_flos': 9832659693696000.0, 'epoch': 5.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='79' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.738474428653717,\n",
       " 'eval_accuracy': 0.6693333333333333,\n",
       " 'eval_f1': 0.6694951527999515,\n",
       " 'eval_precision': 0.6722497668332857,\n",
       " 'eval_recall': 0.6693333333333333,\n",
       " 'eval_runtime': 12.7583,\n",
       " 'eval_samples_per_second': 235.141,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = fine_tune_dataset['test']\n",
    "hyperparams['entity_metrics'] = True\n",
    "test_results=trainer.evaluate(fine_tune_dataset['test'])\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "/home/usama/PycharmProjects/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.8951813578605652,\n",
       " 'eval_accuracy': 0.6158823529411764,\n",
       " 'eval_f1': 0.6149990386013292,\n",
       " 'eval_precision': 0.6151087441671739,\n",
       " 'eval_recall': 0.6158823529411764,\n",
       " 'eval_runtime': 7.3996,\n",
       " 'eval_samples_per_second': 229.742,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset = fine_tune_dataset['dev']\n",
    "validation_results = trainer.evaluate(fine_tune_dataset['dev'])\n",
    "validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL='/best-checkpoint'\n",
    "trainer.save_model(SAVE_PATH+FINAL)\n",
    "with open(SAVE_PATH+FINAL+'/test_results.txt','w') as f:\n",
    "    f.write(pprint.pformat(test_results))\n",
    "with open(SAVE_PATH+FINAL+'/validation_results.txt','w') as f:\n",
    "    f.write(pprint.pformat(validation_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r $SAVE_PATH/checkpoint-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}