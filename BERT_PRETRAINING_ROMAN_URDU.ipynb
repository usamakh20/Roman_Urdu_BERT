{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-15 18:37:39--  https://codeload.github.com/google-research/bert/zip/master\n",
      "Resolving codeload.github.com (codeload.github.com)... 13.127.152.42\n",
      "Connecting to codeload.github.com (codeload.github.com)|13.127.152.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘bert-master1.zip’\n",
      "\n",
      "bert-master1.zip        [  <=>               ] 106.44K   338KB/s    in 0.3s    \n",
      "\n",
      "2020-11-15 18:37:40 (338 KB/s) - ‘bert-master1.zip’ saved [108997]\n",
      "\n",
      "Archive:  bert-master1.zip\n",
      "eedf5716ce1268e56f0a50264a88cafad334ac61\n",
      "   creating: bert-master/\n",
      "  inflating: bert-master/.gitignore  \n",
      "  inflating: bert-master/CONTRIBUTING.md  \n",
      "  inflating: bert-master/LICENSE     \n",
      "  inflating: bert-master/README.md   \n",
      "  inflating: bert-master/__init__.py  \n",
      "  inflating: bert-master/create_pretraining_data.py  \n",
      "  inflating: bert-master/extract_features.py  \n",
      "  inflating: bert-master/modeling.py  \n",
      "  inflating: bert-master/modeling_test.py  \n",
      "  inflating: bert-master/multilingual.md  \n",
      "  inflating: bert-master/optimization.py  \n",
      "  inflating: bert-master/optimization_test.py  \n",
      "  inflating: bert-master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb  \n",
      "  inflating: bert-master/requirements.txt  \n",
      "  inflating: bert-master/run_classifier.py  \n",
      "  inflating: bert-master/run_classifier_with_tfhub.py  \n",
      "  inflating: bert-master/run_pretraining.py  \n",
      "  inflating: bert-master/run_squad.py  \n",
      "  inflating: bert-master/sample_text.txt  \n",
      "  inflating: bert-master/tokenization.py  \n",
      "  inflating: bert-master/tokenization_test.py  \n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: codeload.github.com\" \\\n",
    "    --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36\" \\\n",
    "    --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" \\\n",
    "    --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \\\n",
    "    --header=\"Referer: https://github.com/google-research/bert\" \\\n",
    "    --header=\"Cookie: _octo=GH1.1.68793831.1588906101; _ga=GA1.2.19990328.1588906163; logged_in=no; _gat=1; tz=Asia%2FKarachi\" \\\n",
    "    --header=\"Connection: keep-alive\" \"https://codeload.github.com/google-research/bert/zip/master\" \\\n",
    "    -c -O 'bert-master.zip'\n",
    "\n",
    "!unzip bert-master.zip\n",
    "!rm bert-master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-15 19:32:36--  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.21.48, 216.58.208.240, 216.58.207.112, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.21.48|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 408102251 (389M) [application/zip]\r\n",
      "Saving to: ‘bert-base-uncased.zip’\r\n",
      "\r\n",
      "bert-base-uncased.z  35%[======>             ] 138.01M  80.6KB/s    in 12m 21s \r\n",
      "\r\n",
      "2020-11-15 19:59:58 (191 KB/s) - Read error at byte 144713681/408102251 (Success). Retrying.\r\n",
      "\r\n",
      "--2020-11-15 19:59:59--  (try: 2)  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.21.48|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 206 Partial Content\r\n",
      "Length: 408102251 (389M), 263388570 (251M) remaining [application/zip]\r\n",
      "Saving to: ‘bert-base-uncased.zip’\r\n",
      "\r\n",
      "bert-base-uncased.z 100%[+++++++============>] 389.20M   866KB/s    in 12m 1s  \r\n",
      "\r\n",
      "2020-11-15 20:12:02 (357 KB/s) - ‘bert-base-uncased.zip’ saved [408102251/408102251]\r\n",
      "\r\n",
      "Archive:  bert-base-uncased.zip\r\n",
      "  inflating: bert_model.ckpt.data-00000-of-00001  \r\n",
      "  inflating: bert_config.json        \r\n",
      "  inflating: vocab.txt               \r\n",
      "  inflating: bert_model.ckpt.index   \r\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip \\\n",
    "    -c -O 'bert-base-uncased.zip'\n",
    "\n",
    "!unzip bert-base-uncased.zip -d bert-base-uncased\n",
    "!rm bert-base-uncased.zip\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U tokenizers\n",
    "!pip install tensorflow-gpu==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python tokenization.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python bert-master/create_pretraining_data.py \\\n",
    "    --input_file ROMAN_URDU_DATASET.txt \\\n",
    "    --output_file tf_examples_multi.tfrecord \\\n",
    "    --vocab_file roman-urdu-vocab-uncased.txt \\\n",
    "    --do_lower_case True \\\n",
    "    --max_seq_length 128 \\\n",
    "    --max_predictions_per_seq 10 \\\n",
    "    --masked_lm_prob 0.15 \\\n",
    "    --random_seed 42 \\\n",
    "    --dupe_factor 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "BERT_BASE_DIR='bert-base-uncased'\n",
    "\n",
    "import json\n",
    "with open(BERT_BASE_DIR+'/bert_config.json', \"r+\") as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data[\"vocab_size\"] = sum(1 for line in open('roman-urdu-vocab-cased.txt'))\n",
    "    jsonFile.seek(0)  # rewind\n",
    "    json.dump(data, jsonFile)\n",
    "    jsonFile.truncate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/3E56E27B56E232F7/Users/usama/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/bert-master/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From bert-master/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From bert-master/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n",
      "\r\n",
      "W1115 20:56:44.335807 140718067062592 module_wrapper.py:139] From bert-master/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From bert-master/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n",
      "\r\n",
      "W1115 20:56:44.336080 140718067062592 module_wrapper.py:139] From bert-master/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From /mnt/3E56E27B56E232F7/Users/usama/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/bert-master/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n",
      "\r\n",
      "W1115 20:56:44.336295 140718067062592 module_wrapper.py:139] From /mnt/3E56E27B56E232F7/Users/usama/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/bert-master/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"bert-master/run_pretraining.py\", line 493, in <module>\r\n",
      "    tf.app.run()\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"bert-master/run_pretraining.py\", line 412, in main\r\n",
      "    bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\r\n",
      "  File \"/mnt/3E56E27B56E232F7/Users/usama/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/bert-master/modeling.py\", line 94, in from_json_file\r\n",
      "    text = reader.read()\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\r\n",
      "    self._preread_check()\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\r\n",
      "    compat.as_bytes(self.__name), 1024 * 512)\r\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: /bert_config.json; No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python bert-master/run_pretraining.py \\\n",
    "    --input_file=tf_examples_multi.tfrecord \\\n",
    "    --output_dir=bert_base_roman_urdu \\\n",
    "    --do_train=True \\\n",
    "    --do_eval=True \\\n",
    "    --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n",
    "    --train_batch_size=32 \\\n",
    "    --max_seq_length=128 \\\n",
    "    --max_predictions_per_seq=20 \\\n",
    "    --num_train_steps=10000 \\\n",
    "    --num_warmup_steps=10 \\\n",
    "    --learning_rate=2e-5 \\\n",
    "    --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}