{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\r\n",
      "  Downloading tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2 MB)\r\n",
      "\u001B[K     |████████████████████████████████| 3.2 MB 1.2 MB/s eta 0:00:01\r\n",
      "\u001B[?25hInstalling collected packages: tokenizers\r\n",
      "Successfully installed tokenizers-0.10.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tokenizers\n",
    "!pip install tensorflow-gpu==1.15"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vocab_length = 50000\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-13 21:30:59--  https://codeload.github.com/google-research/bert/zip/master\r\n",
      "Resolving codeload.github.com (codeload.github.com)... 13.233.43.20\r\n",
      "Connecting to codeload.github.com (codeload.github.com)|13.233.43.20|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [application/zip]\r\n",
      "Saving to: ‘bert-master.zip’\r\n",
      "\r\n",
      "bert-master.zip         [  <=>               ] 106.44K   489KB/s    in 0.2s    \r\n",
      "\r\n",
      "2021-02-13 21:31:00 (489 KB/s) - ‘bert-master.zip’ saved [108997]\r\n",
      "\r\n",
      "Archive:  bert-master.zip\r\n",
      "eedf5716ce1268e56f0a50264a88cafad334ac61\r\n",
      "   creating: bert-master/\r\n",
      "  inflating: bert-master/.gitignore  \r\n",
      "  inflating: bert-master/CONTRIBUTING.md  \r\n",
      "  inflating: bert-master/LICENSE     \r\n",
      "  inflating: bert-master/README.md   \r\n",
      "  inflating: bert-master/__init__.py  \r\n",
      "  inflating: bert-master/create_pretraining_data.py  \r\n",
      "  inflating: bert-master/extract_features.py  \r\n",
      "  inflating: bert-master/modeling.py  \r\n",
      "  inflating: bert-master/modeling_test.py  \r\n",
      "  inflating: bert-master/multilingual.md  \r\n",
      "  inflating: bert-master/optimization.py  \r\n",
      "  inflating: bert-master/optimization_test.py  \r\n",
      "  inflating: bert-master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb  \r\n",
      "  inflating: bert-master/requirements.txt  \r\n",
      "  inflating: bert-master/run_classifier.py  \r\n",
      "  inflating: bert-master/run_classifier_with_tfhub.py  \r\n",
      "  inflating: bert-master/run_pretraining.py  \r\n",
      "  inflating: bert-master/run_squad.py  \r\n",
      "  inflating: bert-master/sample_text.txt  \r\n",
      "  inflating: bert-master/tokenization.py  \r\n",
      "  inflating: bert-master/tokenization_test.py  \r\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: codeload.github.com\" \\\n",
    "    --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.135 Safari/537.36\" \\\n",
    "    --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" \\\n",
    "    --header=\"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \\\n",
    "    --header=\"Referer: https://github.com/google-research/bert\" \\\n",
    "    --header=\"Cookie: _octo=GH1.1.68793831.1588906101; _ga=GA1.2.19990328.1588906163; logged_in=no; _gat=1; tz=Asia%2FKarachi\" \\\n",
    "    --header=\"Connection: keep-alive\" \"https://codeload.github.com/google-research/bert/zip/master\" \\\n",
    "    -c -O 'bert-master.zip'\n",
    "\n",
    "!unzip bert-master.zip\n",
    "!rm bert-master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-13 21:31:50--  https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.21.48, 216.58.207.16, 216.58.207.112, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.21.48|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 408102251 (389M) [application/zip]\r\n",
      "Saving to: ‘bert-base-uncased.zip’\r\n",
      "\r\n",
      "bert-base-uncased.z 100%[===================>] 389.20M  1.73MB/s    in 3m 2s   \r\n",
      "\r\n",
      "2021-02-13 21:34:53 (2.14 MB/s) - ‘bert-base-uncased.zip’ saved [408102251/408102251]\r\n",
      "\r\n",
      "Archive:  bert-base-uncased.zip\r\n",
      "  inflating: bert-base-uncased/bert_model.ckpt.data-00000-of-00001  \r\n",
      "  inflating: bert-base-uncased/bert_config.json  \r\n",
      "  inflating: bert-base-uncased/vocab.txt  \r\n",
      "  inflating: bert-base-uncased/bert_model.ckpt.index  \r\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.googleapis.com/bert_models/2020_02_20/uncased_L-12_H-768_A-12.zip \\\n",
    "    -c -O 'bert-base-uncased.zip'\n",
    "\n",
    "!unzip bert-base-uncased.zip -d bert-base-uncased\n",
    "!rm bert-base-uncased.zip\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob('data/' + '*')\n",
    "\n",
    "text_data = []\n",
    "for file in files:\n",
    "    with open(file, 'r') as data:\n",
    "        text = list(filter(lambda x: x != '\\n', data.readlines()))\n",
    "        text_data.append(''.join(text))\n",
    "\n",
    "with open('all_data.txt','w') as f:\n",
    "    f.write('\\n'.join(text_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['./roman-urdu-vocab-uncased_20K-vocab.txt']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tokenizers\n",
    "\n",
    "roman_BWPT = tokenizers.BertWordPieceTokenizer(\n",
    "    # add_special_tokens=True, # This argument doesn't work in the latest version of BertWordPieceTokenizer\n",
    "    unk_token='[UNK]',\n",
    "    sep_token='[SEP]',\n",
    "    cls_token='[CLS]',\n",
    "    clean_text=True,\n",
    "    handle_chinese_chars=True,\n",
    "    strip_accents=True,\n",
    "    lowercase=True,\n",
    "    wordpieces_prefix='##'\n",
    ")\n",
    "\n",
    "roman_BWPT.train(\n",
    "    files=[\"all_data.txt\"],\n",
    "    vocab_size=vocab_length,\n",
    "    min_frequency=3,\n",
    "    limit_alphabet=1000,\n",
    "    show_progress=True,\n",
    "    special_tokens=['[PAD]', '[UNK]', '[CLS]', '[MASK]', '[SEP]']\n",
    ")\n",
    "\n",
    "roman_BWPT.save_model(\".\", \"roman-urdu-vocab-uncased_\"+str(vocab_length))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "english_vocab = open('bert-base-uncased/vocab.txt', 'r').read().split('\\n')\n",
    "roman_urdu_vocab = open('roman-urdu-vocab-uncased_'+str(vocab_length)+'-vocab.txt', 'r').read().split('\\n')\n",
    "\n",
    "common_vocab = list(set(english_vocab).intersection(set(roman_urdu_vocab)))\n",
    "print('No. of common tokens: ',len(common_vocab))\n",
    "\n",
    "augmented_vocab = [''] * len(roman_urdu_vocab)\n",
    "\n",
    "for vocab in common_vocab:\n",
    "    augmented_vocab[english_vocab.index(vocab)] = vocab\n",
    "    roman_urdu_vocab.pop(roman_urdu_vocab.index(vocab))\n",
    "\n",
    "for i in range(len(augmented_vocab)):\n",
    "    if augmented_vocab[i] == '':\n",
    "        augmented_vocab[i] = roman_urdu_vocab.pop(0)\n",
    "\n",
    "with open('augmented_vocab.txt', 'w') as v:\n",
    "    v.write('\\n'.join(augmented_vocab))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "BERT_BASE_DIR='bert-base-uncased'\n",
    "\n",
    "import json\n",
    "with open(BERT_BASE_DIR+'/bert_config.json', \"r+\") as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    data[\"vocab_size\"] = sum(1 for line in open('augmented_vocab.txt'))\n",
    "    jsonFile.seek(0)  # rewind\n",
    "    json.dump(data, jsonFile)\n",
    "    jsonFile.truncate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python bert-master/create_pretraining_data.py \\\n",
    "    --input_file all_data.txt \\\n",
    "    --output_file tf_examples_multi.tfrecord \\\n",
    "    --vocab_file augmented_vocab.txt \\\n",
    "    --do_lower_case True \\\n",
    "    --max_seq_length 128 \\\n",
    "    --max_predictions_per_seq 20 \\\n",
    "    --masked_lm_prob 0.15 \\\n",
    "    --random_seed 42 \\\n",
    "    --dupe_factor 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/3E56E27B56E232F7/Users/usama/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/bert-master/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From bert-master/run_pretraining.py:493: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From bert-master/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n",
      "\r\n",
      "W1115 20:56:44.335807 140718067062592 module_wrapper.py:139] From bert-master/run_pretraining.py:407: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From bert-master/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n",
      "\r\n",
      "W1115 20:56:44.336080 140718067062592 module_wrapper.py:139] From bert-master/run_pretraining.py:407: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n",
      "\r\n",
      "WARNING:tensorflow:From /mnt/3E56E27B56E232F7/Users/usama/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/bert-master/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n",
      "\r\n",
      "W1115 20:56:44.336295 140718067062592 module_wrapper.py:139] From /mnt/3E56E27B56E232F7/Users/usama/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/bert-master/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"bert-master/run_pretraining.py\", line 493, in <module>\r\n",
      "    tf.app.run()\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/absl/app.py\", line 300, in run\r\n",
      "    _run_main(main, args)\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/absl/app.py\", line 251, in _run_main\r\n",
      "    sys.exit(main(argv))\r\n",
      "  File \"bert-master/run_pretraining.py\", line 412, in main\r\n",
      "    bert_config = modeling.BertConfig.from_json_file(FLAGS.bert_config_file)\r\n",
      "  File \"/mnt/3E56E27B56E232F7/Users/usama/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/bert-master/modeling.py\", line 94, in from_json_file\r\n",
      "    text = reader.read()\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 122, in read\r\n",
      "    self._preread_check()\r\n",
      "  File \"/home/usamathescientist/Desktop/PycharmProjects/AIM_LAB/Roman_Urdu_BERT/venv/lib/python3.6/site-packages/tensorflow_core/python/lib/io/file_io.py\", line 84, in _preread_check\r\n",
      "    compat.as_bytes(self.__name), 1024 * 512)\r\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: /bert_config.json; No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python bert-master/run_pretraining.py \\\n",
    "    --input_file=tf_examples_multi.tfrecord \\\n",
    "    --output_dir=bert_bilingual_roman_urdu \\\n",
    "    --do_train=True \\\n",
    "    --do_eval=True \\\n",
    "    --bert_config_file=$BERT_BASE_DIR/bert_config.json \\\n",
    "    --train_batch_size=32 \\\n",
    "    --max_seq_length=128 \\\n",
    "    --max_predictions_per_seq=20 \\\n",
    "    --num_train_steps=100000 \\\n",
    "    --num_warmup_steps=10 \\\n",
    "    --learning_rate=2e-5 \\\n",
    "    --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \\"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}