{'epoch': 30.0,
 'eval_ART_f1': 0.945017182130584,
 'eval_ART_number': 295,
 'eval_ART_precision': 0.9581881533101045,
 'eval_ART_recall': 0.9322033898305084,
 'eval_CONJ_f1': 0.9843104872006606,
 'eval_CONJ_number': 601,
 'eval_CONJ_precision': 0.9770491803278688,
 'eval_CONJ_recall': 0.9916805324459235,
 'eval_DJ_f1': 0.8572731418148655,
 'eval_DJ_number': 1087,
 'eval_DJ_precision': 0.8499095840867993,
 'eval_DJ_recall': 0.8647654093836247,
 'eval_DP_f1': 0.9751745539177658,
 'eval_DP_number': 2580,
 'eval_DP_precision': 0.9759316770186336,
 'eval_DP_recall': 0.9744186046511628,
 'eval_DV_f1': 0.7404580152671756,
 'eval_DV_number': 134,
 'eval_DV_precision': 0.7578125,
 'eval_DV_recall': 0.7238805970149254,
 'eval_ERB_f1': 0.9555741827326069,
 'eval_ERB_number': 1189,
 'eval_ERB_precision': 0.9523809523809523,
 'eval_ERB_recall': 0.95878889823381,
 'eval_ET_f1': 0.8525179856115108,
 'eval_ET_number': 281,
 'eval_ET_precision': 0.8618181818181818,
 'eval_ET_recall': 0.8434163701067615,
 'eval_OUN_f1': 0.8910693497422253,
 'eval_OUN_number': 3040,
 'eval_OUN_precision': 0.9011099899091827,
 'eval_OUN_recall': 0.88125,
 'eval_RON_f1': 0.9448345035105316,
 'eval_RON_number': 503,
 'eval_RON_precision': 0.9534412955465587,
 'eval_RON_recall': 0.9363817097415507,
 'eval_ROPN_f1': 0.7683000604960678,
 'eval_ROPN_number': 824,
 'eval_ROPN_precision': 0.7659831121833535,
 'eval_ROPN_recall': 0.7706310679611651,
 'eval_UM_f1': 0.9614740368509213,
 'eval_UM_number': 300,
 'eval_UM_precision': 0.9663299663299664,
 'eval_UM_recall': 0.9566666666666667,
 'eval_UNCT_f1': 1.0,
 'eval_UNCT_number': 677,
 'eval_UNCT_precision': 1.0,
 'eval_UNCT_recall': 1.0,
 'eval_UX_f1': 0.9441233140655106,
 'eval_UX_number': 782,
 'eval_UX_precision': 0.9483870967741935,
 'eval_UX_recall': 0.9398976982097187,
 'eval_YM_f1': 1.0,
 'eval_YM_number': 14,
 'eval_YM_precision': 1.0,
 'eval_YM_recall': 1.0,
 'eval___f1': 0.0,
 'eval___number': 5,
 'eval___precision': 0.0,
 'eval___recall': 0.0,
 'eval_loss': 0.36080849170684814,
 'eval_overall_accuracy': 0.939073756432247,
 'eval_overall_f1': 0.920325865580448,
 'eval_overall_precision': 0.9231083510377512,
 'eval_overall_recall': 0.9175601039636128,
 'eval_runtime': 3.1778,
 'eval_samples_per_second': 173.708}